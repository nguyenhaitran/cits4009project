---
title: "CITS4009-Individual Project"
author: "Henry Tran"
date: "2024-10-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Install all the required packages for data processing, data transformation and data visualization
library(ggplot2)
library(shiny)
library(gridExtra)
library(reshape2)
library(readxl)
library(dplyr)
```

```{r}
# Read the data
path<-url("https://lms.uwa.edu.au/bbcswebdav/pid-3998436-dt-content-rid-47695412_1/courses/CITS4009_SEM-2_2024/Countries%20and%20death%20causes.csv")
```

# Data Exploratory
```{r}
data<-read.csv(path, header=TRUE)
head(data)
nrow(data)
```
The data has 31 columns and 6840 rows. For the column names, they can be seen that the column names have dot-separated between each word.

```{r}
str(data)
```
```{r}
summary(data)
```
For the first 2 columns, "Entity" and "Code" store different country names and codes. Therefore, to set them as a country as a unique value, it would be the best to convert them into factor

```{r}
data$Entity<-as.factor(data$Entity)
data$Code<-as.factor(data$Code)
data$Year<-as.factor(data$Year)

summary(data)
str(data)
```

```{r}
unique(data$Entity)
```


There are 228 unique entities but there are only 206 codes in this dataset. The reason is because there are some countries and regions do not have unique codes.

There are also no missing data

```{r}
total_missing_value = sum(is.na(data))
total_missing_value
```

While with remaining 29 columns, the maximum numbers are extremely larger than other values. The reason is because the dataset did not only record deaths of countries, but it also recorded the total deaths in groups, regions and in the world. Therefore, if we do the data analysis on the whole dataset, it will create skewness problem. The solution for this would be we can seperated data into different groups: countries, regions and world. I have some examples of the single eda below:

```{r}
boxplot(data$High.systolic.blood.pressure)
```
```{r}
eg1<-log1p(data$Outdoor.air.pollution)
boxplot(eg1)
```



For data exploratory, it will be done using Shiny app

```{r}
# Define UI for application that draws different plot
ui <- fluidPage(
    titlePanel("Visualisation of death in country/region during 1990 - 2019"),
    selectInput("plot_type", "Select plot type:", choices = c("Line plot", "Boxplot", "Heat map", "Correlation plot")),
    sidebarLayout(
        sidebarPanel(
            conditionalPanel(
              condition = "input.plot_type == 'Line plot'",
              checkboxInput("compare", "Compare between 2 countries/regions", FALSE),
            ),
            selectInput("region1", "Choose the first country/region:", choices = unique(data$Entity)),
            conditionalPanel(
              condition = "input.compare == true",
              selectInput("region2", "Choose the second country/region:", choices = unique(data$Entity))
            ),
            conditionalPanel(
              condition = "input.plot_type == 'Line plot'",
              selectInput("reason", "Choose death reason:", choices = names(data)[4:31])
            ),
        ),
        mainPanel(            
          plotOutput("plot1", width = "100%", height = "600px"),
            conditionalPanel(
                condition = "input.compare == true && input.plot_type == 'Line plot'",  # Display plot2 only if compare is checked
                plotOutput("plot2", width = "100%", height = "600px"))
        )
    )
)


# Define the server
server <- function(input, output){
    # Render the histograms
    output$plot1 <- renderPlot({
      region_data<-data[data$Entity==input$region1,]
      # Plot selected death reason
      if (input$plot_type == 'Line plot'){
      ggplot(region_data, aes_string(x="Year", y=input$reason, group = "Entity")) +
          geom_line(color="darkorange") + 
          labs(x="Year", y = input$reason) +
          theme(axis.text.x = element_text(angle = 45, hjust = 1))}
      # Plot the boxplot
      else if (input$plot_type == 'Boxplot'){
        data_melt <- melt(region_data, id.vars = "Year", measure.vars = names(data)[4:31], 
                          variable.name = "death_reason", value.name = "value")
        ggplot(data_melt, aes(x = death_reason, y = value, fill = death_reason)) +
          geom_boxplot() +
          labs(x = "Death Reason", y = "Number of Deaths", title = paste("Boxplot of Death Reasons in", input$region1)) +
          theme_minimal() +
          theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")+
          guides(fill = guide_legend(ncol = 3))
        }
      
      # Plot the Heat Map for selected country
      else if (input$plot_type == 'Heat map'){
        data_melt <- melt(region_data, id.vars = "Year", measure.vars = names(data)[4:31], variable.name = "death_reason", value.name = "value")
        # Create heat map
        ggplot(data_melt, aes(x = Year, y = death_reason, fill = value)) + 
            geom_tile() + 
            scale_fill_gradient(low = "aliceblue", high = "blue") +
            scale_x_discrete(breaks = levels(region_data$Year)) +
            labs(x = "Year", y = "Death Reason", title = paste("Heat Map of Death Reasons in", input$region1)) +
            theme_minimal() +
            theme(axis.text.x = element_text(angle = 45, hjust = 1))
      }
      else if (input$plot_type == "Correlation plot"){
        # Extract the number of death for each death reasons
        numeric_data <- region_data[,4:31]
         
        # Calculate the correlation for all variables
        correlation <- cor(numeric_data)
        
        # Melt the correlation for visualization
        correlation_melted <- melt(correlation)
        
        # Create the correlation heatmap
        ggplot(correlation_melted, aes(x = Var1, y = Var2, fill = value)) +
          geom_tile() +
          scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, limit = c(-1, 1), name = "Correlation") +
          theme_minimal() +
          theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
          labs(title = "Correlation Plot of Death Reasons", x = "Variables", y = "Variables")
      }
    })
    output$plot2 <- renderPlot({ 
      if (input$compare == TRUE && input$plot_type == 'Line plot'){
      region_data<-data[data$Entity==input$region2,]
      # Plot all death reasons
      ggplot(region_data, aes_string(x="Year", y=input$reason, group ="Entity")) + geom_line(color="darkolivegreen") + labs(x="Year", y = input$reason)
    }
  })
}

# Run the Shiny app
shinyApp(ui = ui, server = server)
```
The data needs to be transformed, including divided the data into different groups, including countries, regions. Additionally, log-transformation will be applied for data transformation

## Data Transformation

Firstly, the data will be divided into 2 groups: country and region

There are 28 countries and regions in this data. There are few information we can know if the Entity is a region, including:
- Ends with (WB) or (WHO)
- Start with "World"
- G20
And anything other than this will be considered to be countries.
Here is how we will divide the data into groups

```{r}
region_mask <- grepl("(WB)|(WHO)|^World|^G20|^OECD", data$Entity)

regions<-data[region_mask,]
countries<-data[!region_mask,]
```

```{r}
countries
```

```{r}
regions
```

#Model: Binary classification Sub-Saharan African countries based on death causes
## Data Transformation
For the classification model, the model will classify the Sub-Saharan African countries based on the death causes. The reason to build this model is because the Sub-Saharan African countries could have different death causes compared to countries from other regions.

According to World Bank, there are 48 countries in the low-income groups. Therefore, we will have a column to label them, the country in Sub-Saharan African region will be 1 and 0 for countries from other regions. 

There is a data file of countries in regions from World Bank. This file will be merge with the current data that we are processing

```{r}
#Here is my file path, please change to your filepath to where you downloaded the file
path<-"/Users/henrytran/Documents/UWA_Master-Data-Science/CITS4009/Project/"
```

```{r}
country_groups_file<- paste0(path, "World Bank Country Groups.xlsx")
country_groups_df<-read_excel(country_groups_file, sheet = "List of economies")
country_groups_df
```
The data that we need will include the the Economy, Code and Income group. Therefore, we will keep only 3 columns

```{r}
country_groups_df<-country_groups_df[,c(1,2,4)] #We need the first 3 columns - Economy, Code, Region
country_groups_df
```
Now, we will merge countries dataset with country groups dataset using Code as key, and we keep all the data on the countries dataset
```{r}
countries_merged<-merge(countries, country_groups_df, by.x="Code", by.y="Code", all.x=TRUE)
countries_merged
```
As there are 4 countries do not have Code, including Northen Ireland, Wales, Scotland, and England. They are all in United Kingdom (UK). Now we will double check to see if the total death of UK is the same to the total death of 4 countries
```{r}
countries_merged[countries_merged$Entity=="United Kingdom",]
```


```{r}
total_uk_death <- colSums(countries_merged[countries_merged$Entity=="United Kingdom", 4:31], na.rm = TRUE)
total_uk_death
```

```{r}
four_countries_death <- subset(countries_merged, Entity %in% c("England", "Northern Ireland", "Wales", "Scotland"))
four_countries_death
```
```{r}
total_four_countries_death <- colSums(four_countries_death[, 4:31], na.rm = TRUE)
total_four_countries_death
```
After calculating the total deaths of 4 countries over years, the numbers of death recorded for each reasons are almost the same to the total deaths of UK over years. Therefore, we will drop these 4 countries out of the countries merged dataset.

Now we will calculate the total death of each country for all death causes.
```{r}
countries_merged<-merge(countries, country_groups_df, by.x="Code", by.y="Code")
countries_merged<-countries_merged[,-32]
countries_merged
```
```{r}
# For the data, group the data into entity and income groups, then calculate the total death of each death causes of each country
names(countries_merged)[names(countries_merged) == "Income group"] <- "Income.group"
total_countries_death <- countries_merged %>% group_by(Entity, Income.group) %>% summarise(across(c("Outdoor.air.pollution": "Iron.deficiency"), sum))
total_countries_death
```

After aggregating the model, now we will create a label for each country. As mentioned previously, the countries in  region will be 1 and 0 for countries from other regions. 

```{r}
label_total_countries_death<-total_countries_death
label_total_countries_death$Label<-ifelse(total_countries_death$Income.group == "High income", 1, 0)
label_total_countries_death$Label<-as.factor(label_total_countries_death$Label)
label_total_countries_death
```
```{r}
#check if there is any NA values in the data
sum(is.na(label_total_countries_death))
label_total_countries_death[!complete.cases(label_total_countries_death),]
```
There is one country - Venezuela, which was not classified with income group. As the dataset has 201 rows and only one row has NA values, it is a good decision for us to remove this value
```{r}
label_total_countries_death <- na.omit(label_total_countries_death)
```

```{r}
label_total_countries_death
```



##Building model
- Explain what a null model would look like for classification
- Find all categorical variables and numerical variables
- Expand the dataset with columns built from single variable models
- Plot AUC and select the best performing variables according to AUC

There are 2 models selected for Sub-Saharan African countries classification based on death causes. They are Decision Trees classifier, and Logistic Regression classifier

First of all, the data needs to be divided into 2 groups: training and testing.
```{r}
set.seed(12345)
random_mask<-runif(nrow(label_total_countries_death))<0.8 # 80% of data used for training
train_data<-label_total_countries_death[random_mask,]
test_data<-label_total_countries_death[!random_mask,]
```

```{r}
train_data<-train_data[,3:ncol(train_data)]
train_data
cat("Training dataset size is", dim(train_data))
```
```{r}
test_data<-test_data[,3:ncol(test_data)]
test_data
cat("Testing dataset size is", dim(test_data))
```
```{r}
# we separated the columns, including the responses and all features
responses<- colnames(label_total_countries_death) %in% c("Entity", "Income.group", "Label")
all_features<-colnames(label_total_countries_death)[!responses]
```

### Decision Trees
Single-variate and Multi-Variate models

#### Single-variate model

We will loop through all of the numerical variable to create single variate models with the training data. Then the best single variate model will be selected

Now we will run through all single numerical variables
```{r}
mkPredC<-function(outCol, varCol, appCol){ #training outcomes, training variable and prediction variable
  outCol <- as.vector(outCol)
  varCol <- as.vector(varCol)
  appCol <- as.vector(appCol)
  pOne<-sum(outCol==1)/length(outCol) #how often the outcome is 1 during training
  #print(is.na(varCol))
  #naTab<-table(as.factor(outCol[is.na(varCol)])) 
  #pOneWna<-(naTab/sum(naTab))[pos] #how often the outcome is positive for NA values
  vTab<-table(as.factor(outCol), varCol)
  pOneWv<-(vTab[1,]+ 1.0e-3 *pOne)/(colSums(vTab)+ 1.0e-3) #how often the outcome is 1 with conditioned on levels of training variable
  pred<-pOneWv[appCol] #make prediction by looking up levels of appCol
  #pred[is.na(appCol)]<-pOneWna  #add prediction for NA levels of appCol
  pred[is.na(pred)]<-pOne #add prediction for appCol that were unknown when training
  pred
}

mkPredN<- function(outCol, varCol, appCol){
  varCol <- as.numeric(varCol)  # Ensure it's numeric
  appCol <- as.numeric(appCol)  # Ensure it's numeric
  cuts<-unique(quantile(varCol, probs = seq(0,1,0.1), na.rm=T))
  varC<-cut(varCol, cuts)
  appC<-cut(appCol, cuts)
  mkPredC(outCol, varC, appC)
}
```

```{r}
library('ROCR')

calcAUC <- function(predcol,outcol) {
  perf <- performance(prediction(predcol,outcol==1),'auc')
  as.numeric(perf@y.values)
}
```

```{r}
for(var in all_features) {
  pi <- paste('pred', var, sep='')
  train_data[,pi] <- mkPredN(train_data[["Label"]], as.numeric(unlist(train_data[[var]])), as.numeric(unlist(train_data[[var]])))
  test_data[,pi] <- mkPredN(test_data[["Label"]], as.numeric(unlist(test_data[[var]])),as.numeric(unlist(test_data[[var]])))
  aucTrain <- calcAUC(train_data[,pi], train_data[,"Label"])
  if(aucTrain >= 0.30) {
    aucTest <- calcAUC(test_data[,pi], test_data[,"Label"])
    print(sprintf("%s: trainAUC: %4.3f; testAUC: %4.3f",pi, aucTrain, aucTest))
  }
}
```
When calculating the area under the curve (AUC), it shows that the Secondhand.smoke variable has the highest AUC for training data, with value of 0.383. While looking at the AUC values for testing data, Smoking has the highest AUC with value of 0.318

The best single feature selection is based on the largest log likelihood value
```{r}
# Create a function to calculate the log likelihood
logLikelihood<-function(ytrue, ypred, epsilon = 1e-15){
  ypred <- pmin(pmax(ypred, epsilon), 1 - epsilon)
  sum(ifelse(ytrue==1, log(ypred+epsilon), log(1-ypred-epsilon)), na.rm=T)
}
```

For the best single variable selection, we will calculate the log likelihood to select the best single variable to build the model.
Firstly, we will calculate the Null model on the training dataset
```{r}
logNull<-logLikelihood(train_data[,"Label"], sum(train_data[,"Label"]==0)/nrow(train_data))
cat(logNull)
```

Now we will calculate the log likelihood for all variables
```{r}
one_num_var<-c()
minDrop<-100 # this is as a value to filter the data
for (var in all_features){
  pi<-paste("pred", var, sep='')
  
  devDrop<-2*(logLikelihood(test_data[,"Label"], test_data[[pi]])-logNull)
  if (devDrop>=minDrop){
    print(sprintf("%s, deviance reduction: %g", pi, devDrop))
    one_num_var<-c(one_num_var, pi)
  }
}
```
Among all the vairables satisfied with the condition of log likelihood larger than 100, Smoking is the model with the highest value of 185.363, slightly above the Diet low in Vegitables of 184.449. Therefore, we will use smoking as a variable to build the decision tree classification model.

```{r}
library(rpart)
library(rpart.plot)
decision_singlevar_model <- rpart(Label ~ ., data = train_data[, c("Smoking", "Label")], method = "class")
rpart.plot(decision_singlevar_model)
```

```{r}
print(calcAUC(predict(decision_singlevar_model, train_data)[,2], train_data[,"Label"]))
```

```{r}
print(calcAUC(predict(decision_singlevar_model, test_data)[,2], test_data[,"Label"]))
```

We will build a function to create the confusion matrix for both decision tree and logistic regression classifiers
```{r}
performanceMeasures <- function(pred, truth, name = "model") {
  # Construct confusion matrix ensuring all levels (0 and 1) are present
  ctable <- table(factor(truth, levels = c(0, 1)), factor(pred > 0.5, levels = c(FALSE, TRUE)))
  accuracy <- sum(diag(ctable)) / sum(ctable)
  precision <- ifelse(sum(ctable[, 2]) == 0, 0, ctable[2, 2] / sum(ctable[, 2]))  # Prevent division by 0
  recall <- ifelse(sum(ctable[2, ]) == 0, 0, ctable[2, 2] / sum(ctable[2, ]))  # Prevent division by 0
  f1 <- ifelse(precision + recall == 0, 0, 2 * precision * recall / (precision + recall))  # Handle case where both are 0
  data.frame(model = name, precision = precision, recall = recall, f1 = f1, accuracy = accuracy)
}

pretty_perf_table <- function(model,training,test, feature, model_type) {
  library(pander)
  # setting up Pander Options
  panderOptions("plain.ascii", TRUE)
  panderOptions("keep.trailing.zeros", TRUE)
  panderOptions("table.style", "simple")
  perf_justify <- "lrrrr"
  # comparing performance on training vs. test
  if (model_type == "logistic") {
    pred_train <- predict(model, newdata=training[, feature], type="response")
    pred_test <- predict(model, newdata=test[, feature], type="response")
  } else if (model_type == "decision_tree") {
    # For decision trees, we use the 'type="prob"' to get the probabilities
    pred_train <- predict(model, newdata=training[, feature], type="prob")[, 2]  # second column for class 1
    pred_test <- predict(model, newdata=test[, feature], type="prob")[, 2]  # second column for class 1
  }
  truth_train <- training[["Label"]]
  truth_test <- test[["Label"]]
  
  trainperf_tree <- performanceMeasures(pred_train, truth_train, "logistic, training")
  testperf_tree <- performanceMeasures(pred_test, truth_test, "logistic, test")
  
  perftable <- rbind(trainperf_tree, testperf_tree)
  pandoc.table(perftable, justify = perf_justify)
}
```

```{r}
pretty_perf_table(decision_singlevar_model, train_data, test_data, all_features, "decision_tree")
```

#### Multi-variate model
```{r}
decision_multivar_model <- rpart(Label==1 ~ ., data = train_data[, c(all_features, "Label")], method = "class",control = rpart.control(cp = 0.01))
rpart.plot(decision_multivar_model)
```

```{r}
print(calcAUC(predict(decision_multivar_model, train_data)[,2], train_data[,"Label"]))
```

```{r}
print(calcAUC(predict(decision_multivar_model, test_data)[,2], test_data[,"Label"]))
```

```{r}
pretty_perf_table(decision_multivar_model, train_data, test_data, all_features, "decision_tree")
```


### Logistic Regression
Null model, single variable and full model

This is the Null model

```{r}
sum(train_data$Label==1)/nrow(train_data)
```

This is the single variable

```{r}
log_single_model<-glm(formula=Label~Smoking, data=train_data, family=binomial(link="logit"))
train_data$log_single_pred <- predict(log_single_model, newdata=train_data, type="response")
test_data$log_single_pred <- predict(log_single_model, newdata=test_data, type="response")
```

```{r}
pretty_perf_table(log_single_model, train_data, test_data, "Smoking", "logistic")
```

```{r}
library(knitr)
kable(table(truth=test_data$Label, prediction=test_data$log_single_pred>0.322))
```

For full model
```{r}
formula<-paste("Label", paste(all_features, collapse=" + "), sep=" ~ ")
log_multiple_model<-glm(formula=formula, data=train_data, family=binomial(link="logit"))
train_data$log_multiple_pred <- predict(log_multiple_model, newdata=train_data, type="response")
test_data$log_multiple_pred <- predict(log_multiple_model, newdata=test_data, type="response")
```

```{r}
pretty_perf_table(log_multiple_model, train_data, test_data, all_features, "logistic")
```

```{r}
kable(table(truth=test_data$Label, prediction=test_data$log_multiple_pred>0.322))
```

ROC plot
```{r, fig.asp=1}
library(ROCit)

# Function to plot ROC curves for both logistic regression and decision tree models
plot_roc <- function(predcol1_test, outcol1_test, predcol1_train, outcol1_train, 
                     predcol2_test, outcol2_test, predcol2_train, outcol2_train) {
  
  # ROC for the first model (Logistic Regression)
  roc_1_test <- rocit(score = predcol1_test, class = outcol1_test == 1)
  roc_1_train <- rocit(score = predcol1_train, class = outcol1_train == 1)
  
  # ROC for the second model (Decision Tree)
  roc_2_test <- rocit(score = predcol2_test, class = outcol2_test == 1)
  roc_2_train <- rocit(score = predcol2_train, class = outcol2_train == 1)
  
  # Plot test data for both models
  plot(roc_1_test, col = c("blue", "green"), lwd = 2, legend = FALSE, YIndex = FALSE, values = TRUE, asp = 1)
  lines(roc_2_test$TPR ~ roc_2_test$FPR, col = c("red", "green"), lwd = 2)
  
  # Plot training data as dashed lines
  lines(roc_1_train$TPR ~ roc_1_train$FPR, col = c("blue", "green"), lwd = 2, lty = 2)
  lines(roc_2_train$TPR ~ roc_2_train$FPR, col = c("red","green"), lwd = 2, lty = 2)
  
  # Add a legend
  legend("bottomright", col = c("blue", "red","green"), 
         legend = c("Logistic Test", "Decision Tree Test", "Null Model", "Logistic Train", "Decision Tree Train"),
         lwd = 2,lty = c(1, 1, 2, 2, 2))
}

# Generate predictions for both models on test and training datasets
# For Logistic Regression Model
pred_log_test <- predict(log_multiple_model, newdata = test_data, type = "response")
pred_log_train <- predict(log_multiple_model, newdata = train_data, type = "response")

# For Decision Tree Model (using probability predictions)
pred_tree_test <- predict(decision_multivar_model, newdata = test_data, type = "prob")[, 2]
pred_tree_train <- predict(decision_multivar_model, newdata = train_data, type = "prob")[, 2]

# Now call the plot function with the appropriate data
plot_roc(pred_log_test, test_data$Label, pred_log_train, train_data$Label,
         pred_tree_test, test_data$Label, pred_tree_train, train_data$Label)

```

### Clustering
We will now working on clustering our data. For this one, the total_countries_death data will be used. However, the column Income.group will not be included in this dataset, as it works as a label for the data. Therefore, the dataset will only include country with total death records for each of the death cause.
```{r}
label_total_countries_death<-label_total_countries_death[,-2] #Income.group is the second column
label_total_countries_death<-label_total_countries_death[,-ncol(label_total_countries_death)] #Label is the last column
label_total_countries_death
```

```{r}
all_variables<-colnames(label_total_countries_death)[-1] #except the country column
scale_data<-scale(label_total_countries_death[,all_variables]) # this will be the data where each column has 0 mean and unit standard deviation
```

```{r}
scale_data
```


```{r}
attr(scale_data, "scaled:scale")
```
```{r}
attr(scale_data, "scaled:center")
```

```{r}

```


























